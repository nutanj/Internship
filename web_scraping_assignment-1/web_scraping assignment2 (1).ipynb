{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d9befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b937bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 7\n",
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee56aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b53eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Russia halts participation in an agreement to export grain from Ukrainian ports',\n",
       " 'Brooklyn Nets condemn Kyrie Irving for promotion of antisemitic film',\n",
       " 'These dads drove cross country, raised $156,000 for rare genetic disease  ',\n",
       " \"How 'The 5 Love Languages' stays relevant 30 years after it was first published\",\n",
       " \"I raised 2 successful CEOs and a doctor. Here's the 'unpopular' parenting rule I always used on my kids\",\n",
       " \"Here's a look at some legal and personal ramifications of dying without a will\",\n",
       " \"Issa Rae shares her best career advice and how it's helped her succeed\",\n",
       " 'These people are making real money in Horizon Worlds—even as Meta loses billions',\n",
       " \"What 'millionaire tax' plans on California, Massachusetts ballots mean for taxpayers\",\n",
       " 'A 35-year-old cult classic from John Carpenter keeps finding new audiences',\n",
       " 'From Chipotle to Wendy’s, here are 7 places to score Halloween freebies',\n",
       " \"Twitter is now owned by Elon Musk — here's a brief history its founding to now\",\n",
       " 'The market is moving in-line with seasonal patterns almost perfectly',\n",
       " 'Stocks reporting earnings in the week ahead that tend to top estimates',\n",
       " 'Goldman Sachs analysts say these are the best positioned stocks exiting earnings',\n",
       " 'Derek and Hannah Jeter sign multiyear deal with Jeep to back Grand Wagoneer SUV',\n",
       " 'Cramer on Friday named travel as one of five recession-resistant market leaders that are emerging.',\n",
       " \"Cramer's lightning round: Let's stay with Frontier\",\n",
       " \"Cramer's week ahead: There could be 'real signs' for the Fed to slow down\",\n",
       " 'Co-defendant in SEC civil fraud suit against fake billionaire agrees to settle',\n",
       " 'UN details horrifying accounts of rape, torture, executions by Russian troops',\n",
       " \"Stocks shrug off tech's troubles as Street awaits key inflation data next week\",\n",
       " \"Pro Picks: Watch all of Friday's big stock calls on CNBC\",\n",
       " 'GM temporarily suspends advertising on Twitter following Elon Musk takeover',\n",
       " 'Big Tech falters on dreary earnings — Meta has worst week ever, Amazon falls 13%',\n",
       " '93% of daters want a partner who is emotionally vulnerable',\n",
       " 'Omicron subvariants resistant to key antibody treatments are rising every week',\n",
       " 'Jeep parent Stellantis offering buyouts to some U.S. salaried employees',\n",
       " 'Musk plans Twitter content moderation council as questions about Trump return loom',\n",
       " 'Why Bryan Cranston, Aaron Paul work 17-hour days promoting the Dos Hombres brand']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#headlines scraping\n",
    "headlines=[]\n",
    "for i in soup.find_all('a', class_=\"LatestNews-headline\"):\n",
    "    headlines.append(i.text)\n",
    "    \n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd47587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9133f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '7 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '8 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '9 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '10 Hours Ago',\n",
       " '21 Hours Ago',\n",
       " '22 Hours Ago',\n",
       " '22 Hours Ago',\n",
       " '22 Hours Ago',\n",
       " '24 Hours Ago',\n",
       " '24 Hours Ago',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022',\n",
       " 'October 28, 2022']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time scraping\n",
    "timing=[]\n",
    "for i in soup.find_all('time', class_=\"LatestNews-timestamp\"):\n",
    "    timing.append(i.text)\n",
    "    \n",
    "timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2fbe8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1bffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2022/10/29/russia-halts-participation-in-the-black-sea-grain-initiative.html',\n",
       " 'https://www.cnbc.com/2022/10/29/brooklyn-nets-condemn-kyrie-irving-for-promotion-of-antisemitic-film.html',\n",
       " 'https://www.cnbc.com/2022/10/29/dads-road-trip-for-syngap1-raised-150000-for-rare-genetic-disease-.html',\n",
       " 'https://www.cnbc.com/2022/10/29/how-the-5-love-languages-stays-relevant-30-years-after-publication.html',\n",
       " 'https://www.cnbc.com/2022/10/29/i-raised-2-successful-ceos-and-a-doctor-heres-the-no-1-unpopular-parenting-rule-i-always-used-with-my-kids.html',\n",
       " 'https://www.cnbc.com/2022/10/29/here-are-the-legal-and-personal-ramifications-of-dying-without-a-will.html',\n",
       " 'https://www.cnbc.com/2022/10/29/issa-rae-shares-her-best-career-advice-and-how-its-helped-her-succeed.html',\n",
       " 'https://www.cnbc.com/2022/10/29/metaverse-entrepreneurs-trying-to-make-money-on-metas-horizon-worlds.html',\n",
       " 'https://www.cnbc.com/2022/10/29/what-millionaire-tax-plans-on-california-massachusetts-ballots-mean-for-taxpayers.html',\n",
       " 'https://www.cnbc.com/2022/10/29/john-carpenter-cult-classic-prince-of-darkness-turns-35.html',\n",
       " 'https://www.cnbc.com/2022/10/29/where-to-score-halloween-freebies-chipotle-wendys.html',\n",
       " 'https://www.cnbc.com/2022/10/29/a-brief-history-of-twitter-from-its-founding-in-2006-to-musk-takeover.html',\n",
       " 'https://www.cnbc.com/2022/10/29/the-market-is-moving-in-line-with-seasonal-patterns-almost-perfectly-post-midterms-rally-next.html',\n",
       " 'https://www.cnbc.com/2022/10/29/earnings-results-this-week-these-stocks-tend-to-beat-and-trade-higher.html',\n",
       " 'https://www.cnbc.com/2022/10/29/goldman-sachs-analysts-say-buy-tesla-pepsi.html',\n",
       " 'https://www.cnbc.com/2022/10/28/derek-jeter-promotes-jeep-grand-wagoneer-suv.html',\n",
       " 'https://www.cnbc.com/2022/10/28/jim-cramer-says-he-likes-these-3-travel-stocks.html',\n",
       " 'https://www.cnbc.com/2022/10/28/cramers-lightning-round-lets-stay-with-frontier.html',\n",
       " 'https://www.cnbc.com/2022/10/28/cramers-week-ahead-there-could-be-real-signs-for-the-fed-to-slow-down.html',\n",
       " 'https://www.cnbc.com/2022/10/28/fake-billionaire-justin-costello-co-defendant-settles-sec-complaint.html',\n",
       " 'https://www.cnbc.com/2022/10/28/russia-ukraine-war-un-report-details-accounts-of-rape-torture-and-executions.html',\n",
       " 'https://www.cnbc.com/2022/10/28/stocks-shrugged-off-techs-troubles-as-street-awaits-key-inflation-data.html',\n",
       " 'https://www.cnbc.com/2022/10/28/pro-picks-watch-all-of-fridays-big-stock-calls-on-cnbc.html',\n",
       " 'https://www.cnbc.com/2022/10/28/gm-temporarily-suspends-advertising-on-twitter-following-elon-musk-takeover.html',\n",
       " 'https://www.cnbc.com/2022/10/28/big-tech-falters-on-q3-2022-results-as-meta-has-worst-week-ever.html',\n",
       " 'https://www.cnbc.com/2022/10/28/how-to-be-emotionally-vulnerable-on-a-first-date.html',\n",
       " 'https://www.cnbc.com/2022/10/28/omicron-subvariants-resistant-to-key-antibody-treatments-are-increasing.html',\n",
       " 'https://www.cnbc.com/2022/10/28/chrysler-owner-stellantis-offers-buyouts-to-some-us-employees.html',\n",
       " 'https://www.cnbc.com/2022/10/28/musk-plans-twitter-content-moderation-council-as-questions-about-trump-return-loom.html',\n",
       " 'https://www.cnbc.com/2022/10/28/bryan-cranston-and-aaron-paul-dos-hombres-interview.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#news link scraping\n",
    "links = []\n",
    "for link in soup.find_all('a', class_=\"LatestNews-headline\"):\n",
    "    links.append(link.get('href'))\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cac5d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c9ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 8\n",
    "page1 = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8be91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(page1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2950ca79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Titles scraping\n",
    "titles=[]\n",
    "for i in soup1.find_all('h2', class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e93215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2254de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Authors scraping\n",
    "authors=[]\n",
    "for i in soup1.find_all('span', class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "    \n",
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ed86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97ced392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Published dates scraping\n",
    "dates=[]\n",
    "for i in  soup1.find_all('span', class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    dates.append(i.text)\n",
    "    \n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945eceb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed213e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paper url scraping\n",
    "urls=[]\n",
    "for i in soup1.find_all('a', class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    urls.append(i.get('href'))\n",
    "    \n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ba4705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfabcfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no.9\n",
    "page2 = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b84ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "095b8941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle Barbeque',\n",
       " 'Jungle Jamboree',\n",
       " 'Castle Barbeque',\n",
       " 'Cafe Knosh',\n",
       " 'The Barbeque Company',\n",
       " 'India Grill',\n",
       " 'Delhi Barbeque',\n",
       " 'The Monarch - Bar Be Que Village',\n",
       " 'Indian Grill Room']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#restaurant names scraping\n",
    "rst_name=[]\n",
    "for i in soup2.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    rst_name.append(i.text)\n",
    "    \n",
    "rst_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd752442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Chinese, North Indian',\n",
       " ' North Indian, Asian, Italian',\n",
       " ' Chinese, North Indian',\n",
       " ' Italian, Continental',\n",
       " ' North Indian, Chinese',\n",
       " ' North Indian, Italian',\n",
       " ' North Indian',\n",
       " ' North Indian',\n",
       " ' North Indian, Mughlai']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cuisines scraping\n",
    "cuisines=[]\n",
    "for i in soup2.find_all('span', class_=\"double-line-ellipsis\"):\n",
    "    cuisines.append(i.text.split(\"|\")[-1])\n",
    "cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0db369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#locations scraping\n",
    "locations=[]\n",
    "for i in soup2.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    locations.append(i.text)\n",
    "    \n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "902c148a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '3.9', '3.9', '4.3', '4', '3.9', '3.6', '3.8', '4.3']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings scraping\n",
    "ratings=[]\n",
    "for i in soup2.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d703b54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image url scraping\n",
    "img=[]\n",
    "for i in soup2.find_all('img', class_=\"no-img\"):\n",
    "    img.append(i.get('data-src'))\n",
    "    \n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c0aaf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 10\n",
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe636228",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6430b866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " '31.',\n",
       " '32.',\n",
       " '33.',\n",
       " '34.',\n",
       " '35.',\n",
       " '36.',\n",
       " '37.',\n",
       " '38.',\n",
       " '39.',\n",
       " '40.',\n",
       " '41.',\n",
       " '42.',\n",
       " '43.',\n",
       " '44.',\n",
       " '45.',\n",
       " '46.',\n",
       " '47.',\n",
       " '48.',\n",
       " '49.',\n",
       " '50.',\n",
       " '51.',\n",
       " '52.',\n",
       " '53.',\n",
       " '54.',\n",
       " '55.',\n",
       " '56.',\n",
       " '57.',\n",
       " '58.',\n",
       " '59.',\n",
       " '60.',\n",
       " '61.',\n",
       " '62.',\n",
       " '63.',\n",
       " '64.',\n",
       " '65.',\n",
       " '66.',\n",
       " '67.',\n",
       " '68.',\n",
       " '69.',\n",
       " '70.',\n",
       " '71.',\n",
       " '72.',\n",
       " '73.',\n",
       " '74.',\n",
       " '75.',\n",
       " '76.',\n",
       " '77.',\n",
       " '78.',\n",
       " '79.',\n",
       " '80.',\n",
       " '81.',\n",
       " '82.',\n",
       " '83.',\n",
       " '84.',\n",
       " '85.',\n",
       " '86.',\n",
       " '87.',\n",
       " '88.',\n",
       " '89.',\n",
       " '90.',\n",
       " '91.',\n",
       " '92.',\n",
       " '93.',\n",
       " '94.',\n",
       " '95.',\n",
       " '96.',\n",
       " '97.',\n",
       " '98.',\n",
       " '99.',\n",
       " '100.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rank scraping\n",
    "rank=[]\n",
    "for j in soup.find_all('td', class_=\"gsc_mvt_p\"):\n",
    "    rank.append(j.text)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f3d9c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nature',\n",
       " 'The New England Journal of Medicine',\n",
       " 'Science',\n",
       " 'IEEE/CVF Conference on Computer Vision and Pattern Recognition',\n",
       " 'The Lancet',\n",
       " 'Advanced Materials',\n",
       " 'Nature Communications',\n",
       " 'Cell',\n",
       " 'International Conference on Learning Representations',\n",
       " 'Neural Information Processing Systems',\n",
       " 'JAMA',\n",
       " 'Chemical Reviews',\n",
       " 'Proceedings of the National Academy of Sciences',\n",
       " 'Angewandte Chemie',\n",
       " 'Chemical Society Reviews',\n",
       " 'Journal of the American Chemical Society',\n",
       " 'IEEE/CVF International Conference on Computer Vision',\n",
       " 'Nucleic Acids Research',\n",
       " 'International Conference on Machine Learning',\n",
       " 'Nature Medicine',\n",
       " 'Renewable and Sustainable Energy Reviews',\n",
       " 'Science of The Total Environment',\n",
       " 'Advanced Energy Materials',\n",
       " 'Journal of Clinical Oncology',\n",
       " 'ACS Nano',\n",
       " 'Journal of Cleaner Production',\n",
       " 'Advanced Functional Materials',\n",
       " 'Physical Review Letters',\n",
       " 'Scientific Reports',\n",
       " 'The Lancet Oncology',\n",
       " 'Energy & Environmental Science',\n",
       " 'IEEE Access',\n",
       " 'PLoS ONE',\n",
       " 'Science Advances',\n",
       " 'Journal of the American College of Cardiology',\n",
       " 'Applied Catalysis B: Environmental',\n",
       " 'Nature Genetics',\n",
       " 'BMJ',\n",
       " 'Circulation',\n",
       " 'European Conference on Computer Vision',\n",
       " 'International Journal of Molecular Sciences',\n",
       " 'Nature Materials',\n",
       " 'Chemical engineering journal',\n",
       " 'AAAI Conference on Artificial Intelligence',\n",
       " 'Journal of Materials Chemistry A',\n",
       " 'ACS Applied Materials & Interfaces',\n",
       " 'Nature Biotechnology',\n",
       " 'The Lancet Infectious Diseases',\n",
       " 'Frontiers in Immunology',\n",
       " 'Applied Energy',\n",
       " 'Nano Energy',\n",
       " 'Nature Energy',\n",
       " 'Meeting of the Association for Computational Linguistics (ACL)',\n",
       " 'The Astrophysical Journal',\n",
       " 'Gastroenterology',\n",
       " 'Nature Methods',\n",
       " 'IEEE Transactions on Pattern Analysis and Machine Intelligence',\n",
       " 'Cochrane Database of Systematic Reviews',\n",
       " 'Blood',\n",
       " 'Neuron',\n",
       " 'Nano Letters',\n",
       " 'Morbidity and Mortality Weekly Report',\n",
       " 'European Heart Journal',\n",
       " 'Nature Nanotechnology',\n",
       " 'ACS Catalysis',\n",
       " 'Nature Neuroscience',\n",
       " 'American Economic Review',\n",
       " 'Journal of High Energy Physics',\n",
       " 'IEEE Communications Surveys & Tutorials',\n",
       " 'Annals of Oncology',\n",
       " 'Nutrients',\n",
       " 'Accounts of Chemical Research',\n",
       " 'Immunity',\n",
       " 'Environmental Science & Technology',\n",
       " 'Nature Reviews. Molecular Cell Biology',\n",
       " 'Gut',\n",
       " 'Physical Review D',\n",
       " 'ACS Energy Letters',\n",
       " 'Monthly Notices of the Royal Astronomical Society',\n",
       " 'Conference on Empirical Methods in Natural Language Processing (EMNLP)',\n",
       " 'Clinical Infectious Diseases',\n",
       " 'Cell Metabolism',\n",
       " 'Nature Reviews Immunology',\n",
       " 'Joule',\n",
       " 'Nature Photonics',\n",
       " 'International Journal of Environmental Research and Public Health',\n",
       " 'Environmental Pollution',\n",
       " 'Computers in Human Behavior',\n",
       " 'Frontiers in Microbiology',\n",
       " 'Nature Physics',\n",
       " 'Small',\n",
       " 'Cell Reports',\n",
       " 'Molecular Cell',\n",
       " 'Clinical Cancer Research',\n",
       " 'Bioresource Technology',\n",
       " 'Journal of Business Research',\n",
       " 'Molecular Cancer',\n",
       " 'Sensors',\n",
       " 'Nature Climate Change',\n",
       " 'IEEE Internet of Things Journal']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#publication scraping\n",
    "publication=[]\n",
    "for i in soup.find_all('td', class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "    \n",
    "publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5858041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444',\n",
       " '432',\n",
       " '401',\n",
       " '389',\n",
       " '354',\n",
       " '312',\n",
       " '307',\n",
       " '300',\n",
       " '286',\n",
       " '278',\n",
       " '267',\n",
       " '265',\n",
       " '256',\n",
       " '245',\n",
       " '244',\n",
       " '242',\n",
       " '239',\n",
       " '238',\n",
       " '237',\n",
       " '235',\n",
       " '227',\n",
       " '225',\n",
       " '220',\n",
       " '213',\n",
       " '211',\n",
       " '211',\n",
       " '210',\n",
       " '207',\n",
       " '206',\n",
       " '202',\n",
       " '202',\n",
       " '200',\n",
       " '198',\n",
       " '197',\n",
       " '195',\n",
       " '192',\n",
       " '191',\n",
       " '190',\n",
       " '189',\n",
       " '186',\n",
       " '183',\n",
       " '181',\n",
       " '181',\n",
       " '180',\n",
       " '178',\n",
       " '177',\n",
       " '175',\n",
       " '173',\n",
       " '173',\n",
       " '173',\n",
       " '172',\n",
       " '170',\n",
       " '169',\n",
       " '167',\n",
       " '166',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '165',\n",
       " '164',\n",
       " '164',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '163',\n",
       " '162',\n",
       " '160',\n",
       " '160',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '159',\n",
       " '158',\n",
       " '158',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '155',\n",
       " '154',\n",
       " '153',\n",
       " '153',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '152',\n",
       " '151',\n",
       " '151',\n",
       " '150',\n",
       " '149',\n",
       " '149',\n",
       " '146',\n",
       " '146',\n",
       " '145',\n",
       " '145',\n",
       " '145',\n",
       " '144',\n",
       " '144']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h5 index scraping\n",
    "h5_index=[]\n",
    "for i in soup.find_all('a', class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_index.append(i.text)\n",
    "    \n",
    "h5_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55dfe8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['667',\n",
       " '780',\n",
       " '614',\n",
       " '627',\n",
       " '635',\n",
       " '418',\n",
       " '428',\n",
       " '505',\n",
       " '533',\n",
       " '436',\n",
       " '425',\n",
       " '444',\n",
       " '364',\n",
       " '332',\n",
       " '386',\n",
       " '344',\n",
       " '415',\n",
       " '550',\n",
       " '421',\n",
       " '389',\n",
       " '324',\n",
       " '311',\n",
       " '300',\n",
       " '315',\n",
       " '277',\n",
       " '273',\n",
       " '280',\n",
       " '294',\n",
       " '274',\n",
       " '329',\n",
       " '290',\n",
       " '303',\n",
       " '278',\n",
       " '294',\n",
       " '276',\n",
       " '246',\n",
       " '297',\n",
       " '307',\n",
       " '301',\n",
       " '321',\n",
       " '253',\n",
       " '265',\n",
       " '224',\n",
       " '296',\n",
       " '220',\n",
       " '223',\n",
       " '315',\n",
       " '296',\n",
       " '228',\n",
       " '217',\n",
       " '232',\n",
       " '314',\n",
       " '304',\n",
       " '234',\n",
       " '254',\n",
       " '296',\n",
       " '293',\n",
       " '243',\n",
       " '229',\n",
       " '231',\n",
       " '207',\n",
       " '302',\n",
       " '265',\n",
       " '264',\n",
       " '220',\n",
       " '248',\n",
       " '263',\n",
       " '220',\n",
       " '304',\n",
       " '243',\n",
       " '214',\n",
       " '211',\n",
       " '242',\n",
       " '214',\n",
       " '340',\n",
       " '235',\n",
       " '217',\n",
       " '212',\n",
       " '194',\n",
       " '249',\n",
       " '278',\n",
       " '211',\n",
       " '292',\n",
       " '233',\n",
       " '228',\n",
       " '225',\n",
       " '222',\n",
       " '214',\n",
       " '225',\n",
       " '222',\n",
       " '196',\n",
       " '205',\n",
       " '202',\n",
       " '201',\n",
       " '190',\n",
       " '233',\n",
       " '209',\n",
       " '201',\n",
       " '228',\n",
       " '212']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#h5-median scraping\n",
    "h5_median=[]\n",
    "for i in soup.find_all('span', class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_median.append(i.text)\n",
    "    \n",
    "h5_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "547adad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 1\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page= requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c93d4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3d960c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\" style=\"display: none\"><span class=\"mw-page-title-main\">Main Page</span></h1>\n",
      "<h1><span class=\"mw-headline\" id=\"Welcome_to_Wikipedia\">Welcome to <a href=\"/wiki/Wikipedia\" title=\"Wikipedia\">Wikipedia</a></span></h1>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "<h2>Navigation menu</h2>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span class=\"vector-menu-heading-label\">Personal tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span class=\"vector-menu-heading-label\">Namespaces</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span class=\"vector-menu-heading-label\">Views</span>\n",
      "</h3>\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span class=\"vector-menu-heading-label\">Navigation</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span class=\"vector-menu-heading-label\">Contribute</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span class=\"vector-menu-heading-label\">Tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span class=\"vector-menu-heading-label\">Print/export</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span class=\"vector-menu-heading-label\">In other projects</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span class=\"vector-menu-heading-label\">Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "header_tags= [\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]\n",
    "for tags in soup.find_all(header_tags):\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d372a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nShri Ram Nath Kovind (birth - 1945)\\nTerm of Office: 25 July, 2017 to 25 July, 2022 \\nhttps://ramnathkovind.nic.in\\n',\n",
       " '\\nShri Pranab Mukherjee (1935-2020)\\nTerm of Office: 25 July, 2012 to 25 July, 2017 \\nhttp://pranabmukherjee.nic.in\\n',\n",
       " '\\nSmt Pratibha Devisingh Patil (birth - 1934)\\nTerm of Office: 25 July, 2007 to 25 July, 2012 \\nhttp://pratibhapatil.nic.in\\n',\n",
       " '\\nDR. A.P.J. Abdul Kalam (1931-2015)\\nTerm of Office: 25 July, 2002 to 25 July, 2007 \\nhttp://abdulkalam.nic.in\\n',\n",
       " '\\nShri K. R. Narayanan (1920 - 2005)\\nTerm of Office: 25 July, 1997 to 25 July, 2002 \\n',\n",
       " '\\nDr Shankar Dayal Sharma (1918-1999)\\nTerm of Office: 25 July, 1992 to 25 July, 1997 \\n',\n",
       " '\\nShri R Venkataraman (1910-2009)\\nTerm of Office: 25 July, 1987 to 25 July, 1992 \\n',\n",
       " '\\nGiani Zail Singh (1916-1994)\\nTerm of Office: 25 July, 1982 to 25 July, 1987 \\n',\n",
       " '\\nShri Neelam Sanjiva Reddy (1913-1996)\\nTerm of Office: 25 July, 1977 to 25 July, 1982 \\n',\n",
       " '\\nDr. Fakhruddin Ali Ahmed (1905-1977)\\nTerm of Office: 24 August, 1974 to 11 February, 1977\\n',\n",
       " '\\nShri Varahagiri Venkata Giri (1894-1980)\\nTerm of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974\\n',\n",
       " '\\nDr. Zakir Husain (1897-1969)\\nTerm of Office: 13 May, 1967 to 3 May, 1969\\n',\n",
       " '\\nDr. Sarvepalli Radhakrishnan (1888-1975)\\nTerm of Office: 13 May, 1962 to 13 May, 1967\\n',\n",
       " '\\nDr. Rajendra Prasad (1884-1963) \\nTerm of Office: 26 January, 1950 to 13 May, 1962\\n']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no.4\n",
    "page2 = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page2\n",
    "\n",
    "soup1 = BeautifulSoup(page2.content)\n",
    "\n",
    "name=[]\n",
    "for i in soup1.find_all('div' , class_=\"presidentListing\"):\n",
    "    name.append(i.text)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208a9934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no.3\n",
    "page1 = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2b76c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b924a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n      1.\\n      Kantara\\n(2022)\\n',\n",
       " '\\n      2.\\n      Ramayana: The Legend of Prince Rama\\n(1993)\\n',\n",
       " '\\n      3.\\n      Rocketry: The Nambi Effect\\n(2022)\\n',\n",
       " '\\n      4.\\n      Nayakan\\n(1987)\\n',\n",
       " '\\n      5.\\n      Anbe Sivam\\n(2003)\\n',\n",
       " '\\n      6.\\n      Golmaal\\n(1979)\\n',\n",
       " '\\n      7.\\n      777 Charlie\\n(2022)\\n',\n",
       " '\\n      8.\\n      Jai Bhim\\n(2021)\\n',\n",
       " '\\n      9.\\n      Pariyerum Perumal\\n(2018)\\n',\n",
       " '\\n      10.\\n      3 Idiots\\n(2009)\\n',\n",
       " '\\n      11.\\n      Apur Sansar\\n(1959)\\n',\n",
       " '\\n      12.\\n      Manichitrathazhu\\n(1993)\\n',\n",
       " '\\n      13.\\n      Black Friday\\n(2004)\\n',\n",
       " '\\n      14.\\n      Kumbalangi Nights\\n(2019)\\n',\n",
       " '\\n      15.\\n      Soorarai Pottru\\n(2020)\\n',\n",
       " '\\n      16.\\n      #Home\\n(2021)\\n',\n",
       " '\\n      17.\\n      Taare Zameen Par\\n(2007)\\n',\n",
       " '\\n      18.\\n      C/o Kancharapalem\\n(2018)\\n',\n",
       " '\\n      19.\\n      Kireedam\\n(1989)\\n',\n",
       " '\\n      20.\\n      Dangal\\n(2016)\\n',\n",
       " '\\n      21.\\n      Kaithi\\n(2019)\\n',\n",
       " '\\n      22.\\n      Jersey\\n(2019)\\n',\n",
       " '\\n      23.\\n      96\\n(2018)\\n',\n",
       " '\\n      24.\\n      Asuran\\n(2019)\\n',\n",
       " '\\n      25.\\n      Thevar Magan\\n(1992)\\n',\n",
       " '\\n      26.\\n      Visaaranai\\n(2015)\\n',\n",
       " '\\n      27.\\n      Natsamrat\\n(2016)\\n',\n",
       " '\\n      28.\\n      Drishyam 2\\n(2021)\\n',\n",
       " '\\n      29.\\n      Thalapathi\\n(1991)\\n',\n",
       " '\\n      30.\\n      Pather Panchali\\n(1955)\\n',\n",
       " '\\n      31.\\n      Sarpatta Parambarai\\n(2021)\\n',\n",
       " '\\n      32.\\n      Jaane Bhi Do Yaaro\\n(1983)\\n',\n",
       " '\\n      33.\\n      Thani Oruvan\\n(2015)\\n',\n",
       " '\\n      34.\\n      Sardar Udham\\n(2021)\\n',\n",
       " '\\n      35.\\n      Aparajito\\n(1956)\\n',\n",
       " '\\n      36.\\n      Drishyam\\n(2013)\\n',\n",
       " '\\n      37.\\n      Vada Chennai\\n(2018)\\n',\n",
       " '\\n      38.\\n      Khosla Ka Ghosla!\\n(2006)\\n',\n",
       " '\\n      39.\\n      Sita Ramam\\n(2022)\\n',\n",
       " '\\n      40.\\n      Ratsasan\\n(2018)\\n',\n",
       " '\\n      41.\\n      Chupke Chupke\\n(1975)\\n',\n",
       " '\\n      42.\\n      Anniyan\\n(2005)\\n',\n",
       " '\\n      43.\\n      Peranbu\\n(2018)\\n',\n",
       " '\\n      44.\\n      Mahanati\\n(2018)\\n',\n",
       " '\\n      45.\\n      Satya\\n(1998)\\n',\n",
       " '\\n      46.\\n      Gangs of Wasseypur\\n(2012)\\n',\n",
       " '\\n      47.\\n      Premam\\n(2015)\\n',\n",
       " '\\n      48.\\n      Bangalore Days\\n(2014)\\n',\n",
       " '\\n      49.\\n      Agent Sai Srinivasa Athreya\\n(2019)\\n',\n",
       " '\\n      50.\\n      Super Deluxe\\n(2019)\\n',\n",
       " '\\n      51.\\n      Devasuram\\n(1993)\\n',\n",
       " '\\n      52.\\n      Drishyam\\n(2015)\\n',\n",
       " '\\n      53.\\n      Bhaag Milkha Bhaag\\n(2013)\\n',\n",
       " '\\n      54.\\n      Vikram Vedha\\n(2017)\\n',\n",
       " '\\n      55.\\n      Vikram\\n(2022)\\n',\n",
       " '\\n      56.\\n      Andhadhun\\n(2018)\\n',\n",
       " '\\n      57.\\n      Guide\\n(1965)\\n',\n",
       " '\\n      58.\\n      Tumbbad\\n(2018)\\n',\n",
       " '\\n      59.\\n      Kannathil Muthamittal\\n(2002)\\n',\n",
       " '\\n      60.\\n      Aruvi\\n(2016)\\n',\n",
       " '\\n      61.\\n      Chithram\\n(1988)\\n',\n",
       " '\\n      62.\\n      Zindagi Na Milegi Dobara\\n(2011)\\n',\n",
       " '\\n      63.\\n      Shahid\\n(2012)\\n',\n",
       " '\\n      64.\\n      Sairat\\n(2016)\\n',\n",
       " '\\n      65.\\n      Iruvar\\n(1997)\\n',\n",
       " '\\n      66.\\n      Paan Singh Tomar\\n(2012)\\n',\n",
       " '\\n      67.\\n      Chhichhore\\n(2019)\\n',\n",
       " '\\n      68.\\n      Swades: We, the People\\n(2004)\\n',\n",
       " '\\n      69.\\n      Pyaasa\\n(1957)\\n',\n",
       " '\\n      70.\\n      Chak De! India\\n(2007)\\n',\n",
       " '\\n      71.\\n      Mudhalvan\\n(1999)\\n',\n",
       " '\\n      72.\\n      Munna Bhai M.B.B.S.\\n(2003)\\n',\n",
       " '\\n      73.\\n      Black\\n(2005)\\n',\n",
       " '\\n      74.\\n      Spadikam\\n(1995)\\n',\n",
       " '\\n      75.\\n      Uri: The Surgical Strike\\n(2019)\\n',\n",
       " '\\n      76.\\n      Jo Jeeta Wohi Sikandar\\n(1992)\\n',\n",
       " '\\n      77.\\n      Pudhu Pettai\\n(2006)\\n',\n",
       " '\\n      78.\\n      Dhuruvangal Pathinaaru\\n(2016)\\n',\n",
       " '\\n      79.\\n      Papanasam\\n(2015)\\n',\n",
       " '\\n      80.\\n      Lagaan: Once Upon a Time in India\\n(2001)\\n',\n",
       " '\\n      81.\\n      Queen\\n(2013)\\n',\n",
       " '\\n      82.\\n      Article 15\\n(2019)\\n',\n",
       " '\\n      83.\\n      Talvar\\n(2015)\\n',\n",
       " '\\n      84.\\n      Mandela\\n(2021)\\n',\n",
       " '\\n      85.\\n      Hera Pheri\\n(2000)\\n',\n",
       " '\\n      86.\\n      PK\\n(2014)\\n',\n",
       " '\\n      87.\\n      Soodhu Kavvum\\n(2013)\\n',\n",
       " '\\n      88.\\n      OMG: Oh My God!\\n(2012)\\n',\n",
       " '\\n      89.\\n      Sarfarosh\\n(1999)\\n',\n",
       " '\\n      90.\\n      Sholay\\n(1975)\\n',\n",
       " '\\n      91.\\n      Udaan\\n(2010)\\n',\n",
       " '\\n      92.\\n      Kaakkaa Muttai\\n(2014)\\n',\n",
       " '\\n      93.\\n      Jigarthanda\\n(2014)\\n',\n",
       " '\\n      94.\\n      Barfi!\\n(2012)\\n',\n",
       " '\\n      95.\\n      The Legend of Bhagat Singh\\n(2002)\\n',\n",
       " '\\n      96.\\n      Ustad Hotel\\n(2012)\\n',\n",
       " '\\n      97.\\n      Theeran Adhigaaram Ondru\\n(2017)\\n',\n",
       " '\\n      98.\\n      Rang De Basanti\\n(2006)\\n',\n",
       " '\\n      99.\\n      Baahubali 2: The Conclusion\\n(2017)\\n',\n",
       " '\\n      100.\\n      Angoor\\n(1982)\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie title scraping\n",
    "titles=[]\n",
    "for i in soup.find_all('td' , class_=\"titleColumn\"):\n",
    "    titles.append(i.text)\n",
    "titles[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64410252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n8.5\\n',\n",
       " '\\n8.5\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.4\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.3\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.2\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.1\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n',\n",
       " '\\n8.0\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings scraping\n",
    "ratings=[]\n",
    "for i in soup.find_all('td' , class_=\"ratingColumn imdbRating\"):\n",
    "    ratings.append(i.text)\n",
    "ratings[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e4f6f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2022)',\n",
       " '(1993)',\n",
       " '(2022)',\n",
       " '(1987)',\n",
       " '(2003)',\n",
       " '(1979)',\n",
       " '(2022)',\n",
       " '(2021)',\n",
       " '(2018)',\n",
       " '(2009)',\n",
       " '(1959)',\n",
       " '(1993)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2020)',\n",
       " '(2021)',\n",
       " '(2007)',\n",
       " '(2018)',\n",
       " '(1989)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2019)',\n",
       " '(1992)',\n",
       " '(2015)',\n",
       " '(2016)',\n",
       " '(2021)',\n",
       " '(1991)',\n",
       " '(1955)',\n",
       " '(2021)',\n",
       " '(1983)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1956)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(2022)',\n",
       " '(2018)',\n",
       " '(1975)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(1998)',\n",
       " '(2012)',\n",
       " '(2015)',\n",
       " '(2014)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(1993)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(2017)',\n",
       " '(2022)',\n",
       " '(2018)',\n",
       " '(1965)',\n",
       " '(2018)',\n",
       " '(2002)',\n",
       " '(2016)',\n",
       " '(1988)',\n",
       " '(2011)',\n",
       " '(2012)',\n",
       " '(2016)',\n",
       " '(1997)',\n",
       " '(2012)',\n",
       " '(2019)',\n",
       " '(2004)',\n",
       " '(1957)',\n",
       " '(2007)',\n",
       " '(1999)',\n",
       " '(2003)',\n",
       " '(2005)',\n",
       " '(1995)',\n",
       " '(2019)',\n",
       " '(1992)',\n",
       " '(2006)',\n",
       " '(2016)',\n",
       " '(2015)',\n",
       " '(2001)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(2000)',\n",
       " '(2014)',\n",
       " '(2013)',\n",
       " '(2012)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(2010)',\n",
       " '(2014)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(2002)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2006)',\n",
       " '(2017)',\n",
       " '(1982)']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release year scraping\n",
    "year=[]\n",
    "for i in soup.find_all('span' , class_=\"secondaryInfo\"):\n",
    "    year.append(i.text)\n",
    "year[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "008b4784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>release year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n      1.\\n      Kantara\\n(2022)\\n</td>\n",
       "      <td>(2022)</td>\n",
       "      <td>\\n8.5\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n      2.\\n      Ramayana: The Legend of Prin...</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>\\n8.5\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n      3.\\n      Rocketry: The Nambi Effect\\n...</td>\n",
       "      <td>(2022)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n      4.\\n      Nayakan\\n(1987)\\n</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n      5.\\n      Anbe Sivam\\n(2003)\\n</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>\\n8.4\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\n      96.\\n      Ustad Hotel\\n(2012)\\n</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n      97.\\n      Theeran Adhigaaram Ondru\\n(...</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n      98.\\n      Rang De Basanti\\n(2006)\\n</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n      99.\\n      Baahubali 2: The Conclusion...</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n      100.\\n      Angoor\\n(1982)\\n</td>\n",
       "      <td>(1982)</td>\n",
       "      <td>\\n8.0\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titles release year   rating\n",
       "0                 \\n      1.\\n      Kantara\\n(2022)\\n       (2022)  \\n8.5\\n\n",
       "1   \\n      2.\\n      Ramayana: The Legend of Prin...       (1993)  \\n8.5\\n\n",
       "2   \\n      3.\\n      Rocketry: The Nambi Effect\\n...       (2022)  \\n8.4\\n\n",
       "3                 \\n      4.\\n      Nayakan\\n(1987)\\n       (1987)  \\n8.4\\n\n",
       "4              \\n      5.\\n      Anbe Sivam\\n(2003)\\n       (2003)  \\n8.4\\n\n",
       "..                                                ...          ...      ...\n",
       "95           \\n      96.\\n      Ustad Hotel\\n(2012)\\n       (2012)  \\n8.0\\n\n",
       "96  \\n      97.\\n      Theeran Adhigaaram Ondru\\n(...       (2017)  \\n8.0\\n\n",
       "97       \\n      98.\\n      Rang De Basanti\\n(2006)\\n       (2006)  \\n8.0\\n\n",
       "98  \\n      99.\\n      Baahubali 2: The Conclusion...       (2017)  \\n8.0\\n\n",
       "99               \\n      100.\\n      Angoor\\n(1982)\\n       (1982)  \\n8.0\\n\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe creation\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'titles':titles, 'release year':year, 'rating':ratings})\n",
    "df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2e15b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 2\n",
    "page = requests.get(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b791160",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6cd77af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1.\\nThe Shawshank Redemption\\n(1994)\\n',\n",
       " '\\n2.\\nThe Godfather\\n(1972)\\n',\n",
       " '\\n3.\\nThe Dark Knight\\n(2008)\\n',\n",
       " '\\n4.\\nThe Lord of the Rings: The Return of the King\\n(2003)\\n',\n",
       " \"\\n5.\\nSchindler's List\\n(1993)\\n\",\n",
       " '\\n6.\\nThe Godfather Part II\\n(1974)\\n',\n",
       " '\\n7.\\n12 Angry Men\\n(1957)\\n',\n",
       " '\\n8.\\nPulp Fiction\\n(1994)\\n',\n",
       " '\\n9.\\nInception\\n(2010)\\n',\n",
       " '\\n10.\\nThe Lord of the Rings: The Two Towers\\n(2002)\\n',\n",
       " '\\n11.\\nFight Club\\n(1999)\\n',\n",
       " '\\n12.\\nThe Lord of the Rings: The Fellowship of the Ring\\n(2001)\\n',\n",
       " '\\n13.\\nForrest Gump\\n(1994)\\n',\n",
       " '\\n14.\\nIl buono, il brutto, il cattivo\\n(1966)\\n',\n",
       " '\\n15.\\nThe Matrix\\n(1999)\\n',\n",
       " '\\n16.\\nGoodfellas\\n(1990)\\n',\n",
       " '\\n17.\\nThe Empire Strikes Back\\n(1980)\\n',\n",
       " \"\\n18.\\nOne Flew Over the Cuckoo's Nest\\n(1975)\\n\",\n",
       " '\\n19.\\nInterstellar\\n(2014)\\n',\n",
       " '\\n20.\\nCidade de Deus\\n(2002)\\n',\n",
       " '\\n21.\\nSen to Chihiro no kamikakushi\\n(2001)\\n',\n",
       " '\\n22.\\nSaving Private Ryan\\n(1998)\\n',\n",
       " '\\n23.\\nThe Green Mile\\n(1999)\\n',\n",
       " '\\n24.\\nLa vita è bella\\n(1997)\\n',\n",
       " '\\n25.\\nSe7en\\n(1995)\\n',\n",
       " '\\n26.\\nTerminator 2: Judgment Day\\n(1991)\\n',\n",
       " '\\n27.\\nThe Silence of the Lambs\\n(1991)\\n',\n",
       " '\\n28.\\nStar Wars\\n(1977)\\n',\n",
       " '\\n29.\\nSeppuku\\n(1962)\\n',\n",
       " '\\n30.\\nShichinin no samurai\\n(1954)\\n',\n",
       " \"\\n31.\\nIt's a Wonderful Life\\n(1946)\\n\",\n",
       " '\\n32.\\nGisaengchung\\n(2019)\\n',\n",
       " '\\n33.\\nWhiplash\\n(2014)\\n',\n",
       " '\\n34.\\nThe Intouchables\\n(2011)\\n',\n",
       " '\\n35.\\nThe Prestige\\n(2006)\\n',\n",
       " '\\n36.\\nThe Departed\\n(2006)\\n',\n",
       " '\\n37.\\nThe Pianist\\n(2002)\\n',\n",
       " '\\n38.\\nGladiator\\n(2000)\\n',\n",
       " '\\n39.\\nAmerican History X\\n(1998)\\n',\n",
       " '\\n40.\\nThe Usual Suspects\\n(1995)\\n',\n",
       " '\\n41.\\nLéon\\n(1994)\\n',\n",
       " '\\n42.\\nThe Lion King\\n(1994)\\n',\n",
       " '\\n43.\\nNuovo Cinema Paradiso\\n(1988)\\n',\n",
       " '\\n44.\\nHotaru no haka\\n(1988)\\n',\n",
       " '\\n45.\\nBack to the Future\\n(1985)\\n',\n",
       " '\\n46.\\nApocalypse Now\\n(1979)\\n',\n",
       " '\\n47.\\nAlien\\n(1979)\\n',\n",
       " '\\n48.\\nOnce Upon a Time in the West\\n(1968)\\n',\n",
       " '\\n49.\\nPsycho\\n(1960)\\n',\n",
       " '\\n50.\\nRear Window\\n(1954)\\n']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie title scraping page1\n",
    "mov=[]\n",
    "for i in soup.find_all('h3' , class_=\"lister-item-header\"):\n",
    "    mov.append(i.text)\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f6137b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n9.3\\n',\n",
       " '\\n\\n9.2\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n8.9\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings scraping page 1\n",
    "rating=[]\n",
    "for i in soup.find_all('div' , class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83a5b2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page2 = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&start=51&ref_=adv_nxt')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7610ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e3df751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1.\\nThe Shawshank Redemption\\n(1994)\\n',\n",
       " '\\n2.\\nThe Godfather\\n(1972)\\n',\n",
       " '\\n3.\\nThe Dark Knight\\n(2008)\\n',\n",
       " '\\n4.\\nThe Lord of the Rings: The Return of the King\\n(2003)\\n',\n",
       " \"\\n5.\\nSchindler's List\\n(1993)\\n\",\n",
       " '\\n6.\\nThe Godfather Part II\\n(1974)\\n',\n",
       " '\\n7.\\n12 Angry Men\\n(1957)\\n',\n",
       " '\\n8.\\nPulp Fiction\\n(1994)\\n',\n",
       " '\\n9.\\nInception\\n(2010)\\n',\n",
       " '\\n10.\\nThe Lord of the Rings: The Two Towers\\n(2002)\\n',\n",
       " '\\n11.\\nFight Club\\n(1999)\\n',\n",
       " '\\n12.\\nThe Lord of the Rings: The Fellowship of the Ring\\n(2001)\\n',\n",
       " '\\n13.\\nForrest Gump\\n(1994)\\n',\n",
       " '\\n14.\\nIl buono, il brutto, il cattivo\\n(1966)\\n',\n",
       " '\\n15.\\nThe Matrix\\n(1999)\\n',\n",
       " '\\n16.\\nGoodfellas\\n(1990)\\n',\n",
       " '\\n17.\\nThe Empire Strikes Back\\n(1980)\\n',\n",
       " \"\\n18.\\nOne Flew Over the Cuckoo's Nest\\n(1975)\\n\",\n",
       " '\\n19.\\nInterstellar\\n(2014)\\n',\n",
       " '\\n20.\\nCidade de Deus\\n(2002)\\n',\n",
       " '\\n21.\\nSen to Chihiro no kamikakushi\\n(2001)\\n',\n",
       " '\\n22.\\nSaving Private Ryan\\n(1998)\\n',\n",
       " '\\n23.\\nThe Green Mile\\n(1999)\\n',\n",
       " '\\n24.\\nLa vita è bella\\n(1997)\\n',\n",
       " '\\n25.\\nSe7en\\n(1995)\\n',\n",
       " '\\n26.\\nTerminator 2: Judgment Day\\n(1991)\\n',\n",
       " '\\n27.\\nThe Silence of the Lambs\\n(1991)\\n',\n",
       " '\\n28.\\nStar Wars\\n(1977)\\n',\n",
       " '\\n29.\\nSeppuku\\n(1962)\\n',\n",
       " '\\n30.\\nShichinin no samurai\\n(1954)\\n',\n",
       " \"\\n31.\\nIt's a Wonderful Life\\n(1946)\\n\",\n",
       " '\\n32.\\nGisaengchung\\n(2019)\\n',\n",
       " '\\n33.\\nWhiplash\\n(2014)\\n',\n",
       " '\\n34.\\nThe Intouchables\\n(2011)\\n',\n",
       " '\\n35.\\nThe Prestige\\n(2006)\\n',\n",
       " '\\n36.\\nThe Departed\\n(2006)\\n',\n",
       " '\\n37.\\nThe Pianist\\n(2002)\\n',\n",
       " '\\n38.\\nGladiator\\n(2000)\\n',\n",
       " '\\n39.\\nAmerican History X\\n(1998)\\n',\n",
       " '\\n40.\\nThe Usual Suspects\\n(1995)\\n',\n",
       " '\\n41.\\nLéon\\n(1994)\\n',\n",
       " '\\n42.\\nThe Lion King\\n(1994)\\n',\n",
       " '\\n43.\\nNuovo Cinema Paradiso\\n(1988)\\n',\n",
       " '\\n44.\\nHotaru no haka\\n(1988)\\n',\n",
       " '\\n45.\\nBack to the Future\\n(1985)\\n',\n",
       " '\\n46.\\nApocalypse Now\\n(1979)\\n',\n",
       " '\\n47.\\nAlien\\n(1979)\\n',\n",
       " '\\n48.\\nOnce Upon a Time in the West\\n(1968)\\n',\n",
       " '\\n49.\\nPsycho\\n(1960)\\n',\n",
       " '\\n50.\\nRear Window\\n(1954)\\n',\n",
       " '\\n51.\\nCasablanca\\n(1942)\\n',\n",
       " '\\n52.\\nModern Times\\n(1936)\\n',\n",
       " '\\n53.\\nCity Lights\\n(1931)\\n',\n",
       " '\\n54.\\nCapharnaüm\\n(2018)\\n',\n",
       " '\\n55.\\nJoker\\n(I) (2019)\\n',\n",
       " '\\n56.\\nKimi no na wa.\\n(2016)\\n',\n",
       " '\\n57.\\nSpider-Man: Into the Spider-Verse\\n(2018)\\n',\n",
       " '\\n58.\\nAvengers: Endgame\\n(2019)\\n',\n",
       " '\\n59.\\nAvengers: Infinity War\\n(2018)\\n',\n",
       " '\\n60.\\nCoco\\n(I) (2017)\\n',\n",
       " '\\n61.\\nDjango Unchained\\n(2012)\\n',\n",
       " '\\n62.\\nTop Gun: Maverick\\n(2022)\\n',\n",
       " '\\n63.\\nThe Dark Knight Rises\\n(2012)\\n',\n",
       " '\\n64.\\n3 Idiots\\n(2009)\\n',\n",
       " '\\n65.\\nWALL·E\\n(2008)\\n',\n",
       " '\\n66.\\nThe Lives of Others\\n(2006)\\n',\n",
       " '\\n67.\\nOldeuboi\\n(2003)\\n',\n",
       " '\\n68.\\nMemento\\n(2000)\\n',\n",
       " '\\n69.\\nAmerican Beauty\\n(1999)\\n',\n",
       " '\\n70.\\nMononoke-hime\\n(1997)\\n',\n",
       " '\\n71.\\nBraveheart\\n(1995)\\n',\n",
       " '\\n72.\\nIdi i smotri\\n(1985)\\n',\n",
       " '\\n73.\\nAliens\\n(1986)\\n',\n",
       " '\\n74.\\nAmadeus\\n(1984)\\n',\n",
       " '\\n75.\\nRaiders of the Lost Ark\\n(1981)\\n',\n",
       " '\\n76.\\nDas Boot\\n(1981)\\n',\n",
       " '\\n77.\\nThe Shining\\n(1980)\\n',\n",
       " '\\n78.\\nTengoku to jigoku\\n(1963)\\n',\n",
       " '\\n79.\\nDr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\\n(1964)\\n',\n",
       " '\\n80.\\nWitness for the Prosecution\\n(1957)\\n',\n",
       " '\\n81.\\nPaths of Glory\\n(1957)\\n',\n",
       " '\\n82.\\nSunset Blvd.\\n(1950)\\n',\n",
       " '\\n83.\\nThe Great Dictator\\n(1940)\\n',\n",
       " '\\n84.\\nJagten\\n(2012)\\n',\n",
       " '\\n85.\\nToy Story 3\\n(2010)\\n',\n",
       " '\\n86.\\nInglourious Basterds\\n(2009)\\n',\n",
       " '\\n87.\\nEternal Sunshine of the Spotless Mind\\n(2004)\\n',\n",
       " '\\n88.\\nRequiem for a Dream\\n(2000)\\n',\n",
       " '\\n89.\\nGood Will Hunting\\n(1997)\\n',\n",
       " '\\n90.\\nToy Story\\n(1995)\\n',\n",
       " '\\n91.\\nReservoir Dogs\\n(1992)\\n',\n",
       " '\\n92.\\nOnce Upon a Time in America\\n(1984)\\n',\n",
       " '\\n93.\\nStar Wars: Episode VI - Return of the Jedi\\n(1983)\\n',\n",
       " '\\n94.\\n2001: A Space Odyssey\\n(1968)\\n',\n",
       " '\\n95.\\nLawrence of Arabia\\n(1962)\\n',\n",
       " '\\n96.\\nNorth by Northwest\\n(1959)\\n',\n",
       " '\\n97.\\nVertigo\\n(1958)\\n',\n",
       " \"\\n98.\\nSingin' in the Rain\\n(1952)\\n\",\n",
       " '\\n99.\\nCitizen Kane\\n(1941)\\n',\n",
       " '\\n100.\\nM - Eine Stadt sucht einen Mörder\\n(1931)\\n']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie title scraping for top 100 movies\n",
    "for i in soup2.find_all('h3' , class_=\"lister-item-header\"):\n",
    "    mov.append(i.text)\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ab05be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n9.3\\n',\n",
       " '\\n\\n9.2\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n9.0\\n',\n",
       " '\\n\\n8.9\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.8\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.7\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.6\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.5\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.4\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n',\n",
       " '\\n\\n8.3\\n']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings scraping for 100 movies\n",
    "for i in soup2.find_all('div' , class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fb1fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(2003)',\n",
       " '(1993)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1980)',\n",
       " '(1975)',\n",
       " '(2014)',\n",
       " '(2002)',\n",
       " '(2001)',\n",
       " '(1998)',\n",
       " '(1999)',\n",
       " '(1997)',\n",
       " '(1995)',\n",
       " '(1991)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1962)',\n",
       " '(1954)',\n",
       " '(1946)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(2011)',\n",
       " '(2006)',\n",
       " '(2006)',\n",
       " '(2002)',\n",
       " '(2000)',\n",
       " '(1998)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1994)',\n",
       " '(1988)',\n",
       " '(1988)',\n",
       " '(1985)',\n",
       " '(1979)',\n",
       " '(1979)',\n",
       " '(1968)',\n",
       " '(1960)',\n",
       " '(1954)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#release year scraping page 1\n",
    "year=[]\n",
    "for i in soup.find_all('span' , class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7b8e4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1994)',\n",
       " '(1972)',\n",
       " '(2008)',\n",
       " '(2003)',\n",
       " '(1993)',\n",
       " '(1974)',\n",
       " '(1957)',\n",
       " '(1994)',\n",
       " '(2010)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(2001)',\n",
       " '(1994)',\n",
       " '(1966)',\n",
       " '(1999)',\n",
       " '(1990)',\n",
       " '(1980)',\n",
       " '(1975)',\n",
       " '(2014)',\n",
       " '(2002)',\n",
       " '(2001)',\n",
       " '(1998)',\n",
       " '(1999)',\n",
       " '(1997)',\n",
       " '(1995)',\n",
       " '(1991)',\n",
       " '(1991)',\n",
       " '(1977)',\n",
       " '(1962)',\n",
       " '(1954)',\n",
       " '(1946)',\n",
       " '(2019)',\n",
       " '(2014)',\n",
       " '(2011)',\n",
       " '(2006)',\n",
       " '(2006)',\n",
       " '(2002)',\n",
       " '(2000)',\n",
       " '(1998)',\n",
       " '(1995)',\n",
       " '(1994)',\n",
       " '(1994)',\n",
       " '(1988)',\n",
       " '(1988)',\n",
       " '(1985)',\n",
       " '(1979)',\n",
       " '(1979)',\n",
       " '(1968)',\n",
       " '(1960)',\n",
       " '(1954)',\n",
       " '(1942)',\n",
       " '(1936)',\n",
       " '(1931)',\n",
       " '(2018)',\n",
       " '(I) (2019)',\n",
       " '(2016)',\n",
       " '(2018)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(I) (2017)',\n",
       " '(2012)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(2009)',\n",
       " '(2008)',\n",
       " '(2006)',\n",
       " '(2003)',\n",
       " '(2000)',\n",
       " '(1999)',\n",
       " '(1997)',\n",
       " '(1995)',\n",
       " '(1985)',\n",
       " '(1986)',\n",
       " '(1984)',\n",
       " '(1981)',\n",
       " '(1981)',\n",
       " '(1980)',\n",
       " '(1963)',\n",
       " '(1964)',\n",
       " '(1957)',\n",
       " '(1957)',\n",
       " '(1950)',\n",
       " '(1940)',\n",
       " '(2012)',\n",
       " '(2010)',\n",
       " '(2009)',\n",
       " '(2004)',\n",
       " '(2000)',\n",
       " '(1997)',\n",
       " '(1995)',\n",
       " '(1992)',\n",
       " '(1984)',\n",
       " '(1983)',\n",
       " '(1968)',\n",
       " '(1962)',\n",
       " '(1959)',\n",
       " '(1958)',\n",
       " '(1952)',\n",
       " '(1941)',\n",
       " '(1931)']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relese year scrapingfor100 movies\n",
    "for i in soup2.find_all('span' , class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b9d25aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>release year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n1.\\nThe Shawshank Redemption\\n(1994)\\n</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>\\n\\n9.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n2.\\nThe Godfather\\n(1972)\\n</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>\\n\\n9.2\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n3.\\nThe Dark Knight\\n(2008)\\n</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>\\n\\n9.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n4.\\nThe Lord of the Rings: The Return of the...</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>\\n\\n9.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n5.\\nSchindler's List\\n(1993)\\n</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>\\n\\n9.0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>\\n96.\\nNorth by Northwest\\n(1959)\\n</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>\\n\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>\\n97.\\nVertigo\\n(1958)\\n</td>\n",
       "      <td>(1958)</td>\n",
       "      <td>\\n\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>\\n98.\\nSingin' in the Rain\\n(1952)\\n</td>\n",
       "      <td>(1952)</td>\n",
       "      <td>\\n\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>\\n99.\\nCitizen Kane\\n(1941)\\n</td>\n",
       "      <td>(1941)</td>\n",
       "      <td>\\n\\n8.3\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>\\n100.\\nM - Eine Stadt sucht einen Mörder\\n(19...</td>\n",
       "      <td>(1931)</td>\n",
       "      <td>\\n\\n8.3\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titles release year     rating\n",
       "0            \\n1.\\nThe Shawshank Redemption\\n(1994)\\n       (1994)  \\n\\n9.3\\n\n",
       "1                       \\n2.\\nThe Godfather\\n(1972)\\n       (1972)  \\n\\n9.2\\n\n",
       "2                     \\n3.\\nThe Dark Knight\\n(2008)\\n       (2008)  \\n\\n9.0\\n\n",
       "3   \\n4.\\nThe Lord of the Rings: The Return of the...       (2003)  \\n\\n9.0\\n\n",
       "4                    \\n5.\\nSchindler's List\\n(1993)\\n       (1993)  \\n\\n9.0\\n\n",
       "..                                                ...          ...        ...\n",
       "95                \\n96.\\nNorth by Northwest\\n(1959)\\n       (1959)  \\n\\n8.3\\n\n",
       "96                           \\n97.\\nVertigo\\n(1958)\\n       (1958)  \\n\\n8.3\\n\n",
       "97               \\n98.\\nSingin' in the Rain\\n(1952)\\n       (1952)  \\n\\n8.3\\n\n",
       "98                      \\n99.\\nCitizen Kane\\n(1941)\\n       (1941)  \\n\\n8.3\\n\n",
       "99  \\n100.\\nM - Eine Stadt sucht einen Mörder\\n(19...       (1931)  \\n\\n8.3\\n\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe creation\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'titles':mov, 'release year':year, 'rating':rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8df0abd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question no. 5(A)\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "918b9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f2e8f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['England',\n",
       " 'New Zealand',\n",
       " 'India',\n",
       " 'Pakistan',\n",
       " 'Australia',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'West Indies',\n",
       " 'Afghanistan']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 ODI team scraping\n",
    "team =[]\n",
    "for i in soup.find_all('span', class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "    \n",
    "team[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c86bd3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1\\n\\n\\nEngland\\nENG\\n\\n27\\n3,226\\n\\n                            119\\n                            \\n\\n\\n']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#match\n",
    "match=[]\n",
    "first= soup.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text\n",
    "match.append(first.text)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb88bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1\\n\\n\\nEngland\\nENG\\n\\n27\\n3,226\\n\\n                            119\\n                            \\n\\n\\n',\n",
       " '\\n2\\n\\n\\nNew Zealand\\nNZ\\n\\n22\\n2,508\\n114\\n',\n",
       " '\\n3\\n\\n\\nIndia\\nIND\\n\\n34\\n3,802\\n112\\n',\n",
       " '\\n4\\n\\n\\nPakistan\\nPAK\\n\\n22\\n2,354\\n107\\n',\n",
       " '\\n5\\n\\n\\nAustralia\\nAUS\\n\\n29\\n3,071\\n106\\n',\n",
       " '\\n6\\n\\n\\nSouth Africa\\nSA\\n\\n24\\n2,392\\n100\\n',\n",
       " '\\n7\\n\\n\\nBangladesh\\nBAN\\n\\n30\\n2,753\\n92\\n',\n",
       " '\\n8\\n\\n\\nSri Lanka\\nSL\\n\\n29\\n2,658\\n92\\n',\n",
       " '\\n9\\n\\n\\nWest Indies\\nWI\\n\\n41\\n2,902\\n71\\n',\n",
       " '\\n10\\n\\n\\nAfghanistan\\nAFG\\n\\n18\\n1,238\\n69\\n']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup.find_all('tr', class_=\"table-body\"):\n",
    "    match.append(i.text)\n",
    "    \n",
    "match[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d08b2ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 5(b)\n",
    "page1 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11893d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(page1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72913c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBabar Azam\\n\\n\\n\\n\\n\\n\\nPAK\\n                    \\n\\n\\n890\\n\\n\\n\\n\\n                                898 v West Indies, 10/06/2022\\n                        \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batmen=[]\n",
    "first= soup1.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "131c2435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBabar Azam\\n\\n\\n\\n\\n\\n\\nPAK\\n                    \\n\\n\\n890\\n\\n\\n\\n\\n                                898 v West Indies, 10/06/2022\\n                        \\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batmen.append(first.text)\n",
    "batmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9e3acb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBabar Azam\\n\\n\\n\\n\\n\\n\\nPAK\\n                    \\n\\n\\n890\\n\\n\\n\\n\\n                                898 v West Indies, 10/06/2022\\n                        \\n\\n\\n\\n\\n',\n",
       " '\\n\\n\\n\\n                                    2\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nImam-ul-Haq\\n\\n\\n\\nPAK\\n\\n779\\n\\n                                815 v West Indies, 12/06/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    3\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nRassie van der Dussen\\n\\n\\n\\nSA\\n\\n766\\n\\n                                796 v England, 19/07/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    4\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nQuinton de Kock\\n\\n\\n\\nSA\\n\\n759\\n\\n                                813 v Sri Lanka, 10/03/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    5\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nJonny Bairstow\\n\\n\\n\\nENG\\n\\n732\\n\\n                                796 v India, 26/03/2021\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    6\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved up in the rankings since the previous rankings update\\n\\n\\n\\n\\nDavid Warner\\n\\n\\n\\nAUS\\n\\n725\\n\\n                                880 v Pakistan, 26/01/2017\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    7\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved down in the rankings since the previous rankings update\\n\\n\\n\\n\\nVirat Kohli\\n\\n\\n\\nIND\\n\\n722\\n\\n                                911 v England, 12/07/2018\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    8\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nRohit Sharma\\n\\n\\n\\nIND\\n\\n718\\n\\n                                885 v Sri Lanka, 06/07/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    9\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nRoss Taylor\\n\\n\\n\\nNZ\\n\\n701\\n\\n                                841 v Bangladesh, 05/06/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    10\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nSteve Smith\\n\\n\\n\\nAUS\\n\\n697\\n\\n                                752 v Pakistan, 22/01/2017\\n                        \\n']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup1.find_all('tr', class_=\"table-body\"):\n",
    "    batmen.append(i.text)\n",
    "    \n",
    "batmen[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf332537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 bowler question 5(c)\n",
    "page2 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11ed0990",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0709bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrent Boult\\n\\n\\n\\n\\n\\n\\nNZ\\n                    \\n\\n\\n775\\n\\n\\n\\n\\n                                775 v Australia, 11/09/2022\\n                        \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler=[]\n",
    "first= soup2.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce90877d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrent Boult\\n\\n\\n\\n\\n\\n\\nNZ\\n                    \\n\\n\\n775\\n\\n\\n\\n\\n                                775 v Australia, 11/09/2022\\n                        \\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler.append(first.text)\n",
    "bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "243ce96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTrent Boult\\n\\n\\n\\n\\n\\n\\nNZ\\n                    \\n\\n\\n775\\n\\n\\n\\n\\n                                775 v Australia, 11/09/2022\\n                        \\n\\n\\n\\n\\n',\n",
       " '\\n\\n\\n\\n                                    2\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nJosh Hazlewood\\n\\n\\n\\nAUS\\n\\n718\\n\\n                                733 v England, 26/01/2018\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    3\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMujeeb Ur Rahman\\n\\n\\n\\nAFG\\n\\n676\\n\\n                                712 v Ireland, 24/01/2021\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    4\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nShaheen Afridi\\n\\n\\n\\nPAK\\n\\n661\\n\\n                                688 v West Indies, 10/06/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    5\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMohammad Nabi\\n\\n\\n\\nAFG\\n\\n657\\n\\n                                657 v Zimbabwe, 09/06/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    6\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMehedi Hasan\\n\\n\\n\\nBAN\\n\\n655\\n\\n                                725 v Sri Lanka, 25/05/2021\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    7\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMatt Henry\\n\\n\\n\\nNZ\\n\\n654\\n\\n                                691 v Bangladesh, 26/03/2021\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    8\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMitchell Starc\\n\\n\\n\\nAUS\\n\\n653\\n\\n                                783 v New Zealand, 29/03/2015\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    9\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nRashid Khan\\n\\n\\n\\nAFG\\n\\n651\\n\\n                                806 v Pakistan, 21/09/2018\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    10\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nJasprit Bumrah\\n\\n\\n\\nIND\\n\\n642\\n\\n                                841 v West Indies, 01/11/2018\\n                        \\n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup2.find_all('tr', class_=\"table-body\"):\n",
    "    bowler.append(i.text)\n",
    "    \n",
    "bowler[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71828161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question6(a)\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ff92af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f95b031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'South Africa',\n",
       " 'England',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Pakistan',\n",
       " 'Ireland',\n",
       " 'Sri Lanka']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 odi womens' team\n",
    "wteam =[]\n",
    "for i in soup.find_all('span', class_=\"u-hide-phablet\"):\n",
    "    wteam.append(i.text)\n",
    "    \n",
    "wteam[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fb6d7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1\\n\\n\\nAustralia\\nAUS\\n\\n18\\n3,061\\n\\n                            170\\n                            \\n\\n\\n']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match=[]\n",
    "first= soup.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text\n",
    "match.append(first.text)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51223881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1\\n\\n\\nAustralia\\nAUS\\n\\n18\\n3,061\\n\\n                            170\\n                            \\n\\n\\n',\n",
       " '\\n2\\n\\n\\nSouth Africa\\nSA\\n\\n26\\n3,098\\n119\\n',\n",
       " '\\n3\\n\\n\\nEngland\\nENG\\n\\n25\\n2,904\\n116\\n',\n",
       " '\\n4\\n\\n\\nIndia\\nIND\\n\\n27\\n2,820\\n104\\n',\n",
       " '\\n5\\n\\n\\nNew Zealand\\nNZ\\n\\n24\\n2,425\\n101\\n',\n",
       " '\\n6\\n\\n\\nWest Indies\\nWI\\n\\n24\\n2,334\\n97\\n',\n",
       " '\\n7\\n\\n\\nBangladesh\\nBAN\\n\\n12\\n932\\n78\\n',\n",
       " '\\n8\\n\\n\\nPakistan\\nPAK\\n\\n21\\n1,237\\n59\\n',\n",
       " '\\n9\\n\\n\\nIreland\\nIRE\\n\\n11\\n516\\n47\\n',\n",
       " '\\n10\\n\\n\\nSri Lanka\\nSL\\n\\n8\\n353\\n44\\n']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup.find_all('tr', class_=\"table-body\"):\n",
    "    match.append(i.text)\n",
    "    \n",
    "match[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73addb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 6.(b)\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e686e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cf1ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlyssa Healy\\n\\n\\n\\n\\n\\n\\nAUS\\n                    \\n\\n\\n785\\n\\n\\n\\n\\n                                785 v England, 03/04/2022\\n                        \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batting=[]\n",
    "first= soup.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "289f7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlyssa Healy\\n\\n\\n\\n\\n\\n\\nAUS\\n                    \\n\\n\\n785\\n\\n\\n\\n\\n                                785 v England, 03/04/2022\\n                        \\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batting.append(first.text)\n",
    "batting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "403f1f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n(0)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAlyssa Healy\\n\\n\\n\\n\\n\\n\\nAUS\\n                    \\n\\n\\n785\\n\\n\\n\\n\\n                                785 v England, 03/04/2022\\n                        \\n\\n\\n\\n\\n',\n",
       " '\\n\\n\\n\\n                                    2\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nBeth Mooney\\n\\n\\n\\nAUS\\n\\n749\\n\\n                                748 v England, 03/04/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    3\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nLaura Wolvaardt\\n\\n\\n\\nSA\\n\\n732\\n\\n                                741 v Australia, 22/03/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    4\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nNatalie Sciver\\n\\n\\n\\nENG\\n\\n725\\n\\n                                755 v South Africa, 15/07/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    5\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nHarmanpreet Kaur\\n\\n\\n\\nIND\\n\\n716\\n\\n                                731 v England, 21/09/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    6\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nSmriti Mandhana\\n\\n\\n\\nIND\\n\\n714\\n\\n                                797 v England, 28/02/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    7\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nMeg Lanning\\n\\n\\n\\nAUS\\n\\n710\\n\\n                                834 v New Zealand, 24/02/2016\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    8\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nRachael Haynes\\n\\n\\n\\nAUS\\n\\n701\\n\\n                                713 v West Indies, 15/03/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    9\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nAmy Satterthwaite\\n\\n\\n\\nNZ\\n\\n661\\n\\n                                756 v Australia, 02/03/2017\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    10\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nChamari Athapaththu\\n\\n\\n\\nSL\\n\\n655\\n\\n                                691 v South Africa, 14/02/2019\\n                        \\n']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup.find_all('tr', class_=\"table-body\"):\n",
    "    batting.append(i.text)\n",
    "    \n",
    "batting[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "189c5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question 6(c)\n",
    "page2 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d98e81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(page2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d64b27d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                            1\\n                        \\n\\n\\n\\n\\n(4)\\nThis player has moved up in the rankings since the previous rankings update\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHayley Matthews\\n\\n\\n\\n\\n\\n\\nWI\\n                    \\n\\n\\n380\\n\\n\\n\\n\\n                                380 v New Zealand, 25/09/2022\\n                        \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rounder=[]\n",
    "first= soup2.find('tr', class_=\"rankings-block__banner\")\n",
    "first.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93562ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n\\n\\n(4)\\nThis player has moved up in the rankings since the previous rankings update\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHayley Matthews\\n\\n\\n\\n\\n\\n\\nWI\\n                    \\n\\n\\n380\\n\\n\\n\\n\\n                                380 v New Zealand, 25/09/2022\\n                        \\n\\n\\n\\n\\n']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rounder.append(first.text)\n",
    "all_rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "003ac0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\n\\n                            1\\n                        \\n\\n\\n\\n\\n(4)\\nThis player has moved up in the rankings since the previous rankings update\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHayley Matthews\\n\\n\\n\\n\\n\\n\\nWI\\n                    \\n\\n\\n380\\n\\n\\n\\n\\n                                380 v New Zealand, 25/09/2022\\n                        \\n\\n\\n\\n\\n',\n",
       " '\\n\\n\\n\\n                                    2\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved down in the rankings since the previous rankings update\\n\\n\\n\\n\\nEllyse Perry\\n\\n\\n\\nAUS\\n\\n374\\n\\n                                548 v West Indies, 11/09/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    3\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved down in the rankings since the previous rankings update\\n\\n\\n\\n\\nNatalie Sciver\\n\\n\\n\\nENG\\n\\n357\\n\\n                                395 v South Africa, 11/07/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    4\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved down in the rankings since the previous rankings update\\n\\n\\n\\n\\nAmelia Kerr\\n\\n\\n\\nNZ\\n\\n356\\n\\n                                356 v West Indies, 25/09/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    5\\n                                \\n\\n\\n\\n\\n(1)\\nThis player has moved down in the rankings since the previous rankings update\\n\\n\\n\\n\\nMarizanne Kapp\\n\\n\\n\\nSA\\n\\n349\\n\\n                                419 v West Indies, 10/09/2021\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    6\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nDeepti Sharma\\n\\n\\n\\nIND\\n\\n322\\n\\n                                397 v South Africa, 09/10/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    7\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nAshleigh Gardner\\n\\n\\n\\nAUS\\n\\n270\\n\\n                                279 v West Indies, 30/03/2022\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    8\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nJess Jonassen\\n\\n\\n\\nAUS\\n\\n246\\n\\n                                308 v West Indies, 11/09/2019\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    9\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nJhulan Goswami\\n\\n\\n\\nIND\\n\\n214\\n\\n                                308 v Australia, 02/02/2016\\n                        \\n',\n",
       " '\\n\\n\\n\\n                                    10\\n                                \\n\\n\\n(0)\\n\\n\\n\\n\\nKatherine Brunt\\n\\n\\n\\nENG\\n\\n207\\n\\n                                296 v Australia, 03/02/2022\\n                        \\n']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in soup2.find_all('tr', class_=\"table-body\"):\n",
    "    all_rounder.append(i.text)\n",
    "    \n",
    "all_rounder[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
